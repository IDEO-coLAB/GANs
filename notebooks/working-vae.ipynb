{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# img_directory = '/Users/rwilliams/Desktop/celeba/training'\n",
    "img_directory = '/home/ec2-user/training-data/img_align_celeba'\n",
    "model_save_path = '/home/ec2-user/tf-checkpoints/vae-celeba/checkpoint.ckpt'\n",
    "outputs_directory = '/home/ec2-user/outputs/vae-celeba'\n",
    "log_directory = '/home/ec2-user/tf-logs/vae-celeba'\n",
    "batch_size = 64\n",
    "training_set_size = 5000\n",
    "img_size = 128\n",
    "# import packages for jupyter\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "from utils import imshow, resize_crop, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load training data\n",
    "\n",
    "training = np.array([resize_crop(load_img(i+1, img_directory), (img_size, img_size)) for i in range(training_set_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model and load weights\n",
    "\n",
    "import tensorflow as tf\n",
    "from autoencoder import Autoencoder\n",
    "tf.reset_default_graph()\n",
    "\n",
    "vae = Autoencoder(img_shape=(img_size, img_size, 3))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, img_size, img_size, 3])\n",
    "encoder = vae.encoder(X)\n",
    "decoder = vae.decoder(encoder)\n",
    "\n",
    "latent_loss = vae.latent_loss()\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=vae.logits)\n",
    "reconstruction_loss = tf.reduce_mean(xentropy)\n",
    "loss = reconstruction_loss + latent_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create or restore session\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "try:\n",
    "    print('trying to restore session')\n",
    "    saver.restore(sess, model_save_path)\n",
    "    print('restored session')\n",
    "except:\n",
    "    print('failed to restore session, creating a new one')\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "# write logs for tensorboard\n",
    "writer = tf.summary.FileWriter(log_directory, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect data for tensorboard\n",
    "latent_loss_summary = tf.summary.scalar('latent_loss', latent_loss)\n",
    "reconstruction_loss_summary = tf.summary.scalar('reconstruction_loss', reconstruction_loss)\n",
    "loss_summary = tf.summary.scalar('total_loss', loss)\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "epochs = 10000\n",
    "batches = int(float(training_set_size) / batch_size) \n",
    "\n",
    "img_idx = 0\n",
    "print('training', flush=True)\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print ('epoch %s ' % epoch, end='', flush=True)\n",
    "    for batch in range(batches):\n",
    "        print('.', end='', flush=True)\n",
    "        feed = training[batch*batch_size:(batch+1)*batch_size]\n",
    "        sess.run(training_op, feed_dict={X: feed})\n",
    "        \n",
    "    if (epoch % 1 == 0):\n",
    "        print('saving session', flush=True)\n",
    "        saver.save(sess, model_save_path)\n",
    "        \n",
    "        xfeed = training[:batch_size]\n",
    "        summary = merged_summary.eval(feed_dict={X: xfeed})\n",
    "        writer.add_summary(summary, epoch) \n",
    "\n",
    "        example = decoder.eval(feed_dict={X: training[:1]})\n",
    "        img_save_path = os.path.join(outputs_directory, '%06d.jpg' % img_idx)\n",
    "        img_idx += 1\n",
    "        sp.misc.imsave(img_save_path, example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# y = sess.run(decoder, feed_dict={X: training[idx:idx+4]})\n",
    "# y.shape\n",
    "# imshow(y[0:4])\n",
    "# imshow(training[idx:idx+4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r = np.random.normal(size=(8,128), scale=1.0)\n",
    "# y = sess.run(decoder, feed_dict={encoder: r})\n",
    "# imshow(y[0:8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
